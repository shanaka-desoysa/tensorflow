{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. \n",
    "Please find 2 files from Google’s tutorials sets. I used file mnist2.py in class yesterday and for preparation of my notes. If you read the file carefully you will see that you can run it in at least two modes. The way it is setup now it selects one learning rate and one particular neural network architecture and generates TensorBoard graph in a particular directory. One problem with this script is that its accuracy is surprisingly low. Such complex architecture and so many lines of code and we get 70% or lower accuracy. We expected more from Convolutional Neural Networks.  File cnn_mnist.py is practically the same, at least it does all the same things, creates the same architecture, sets the same or similar parameters, but does much better job. Its accuracy is in high 90%-s. Run two files compare results and then fix the first file (mnist2.py) based on what you saw in file cnn_mnist.py. Capture the Accuracy and Cross Entropy (summary) graphs from the corrected version of mnist2.py and provide working and fixed version of that file. Please describe in detail experiments you undertook and fixes you made. (45%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/original-TensorBoard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/original-TensorBoard-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we are benchmarking with cnn_mnist.py program, choose the parameters similar to that program. So we can compare apples to apples.\n",
    "Iterations: 500 <br>\n",
    "Learning rate: .005<br>\n",
    "use_two_fc: True<br>\n",
    "use_two_conv: True<br>\n",
    "![](img/lr005_steps500.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias values for both conv_layer and fc_layer have been set to constant 0.1. This could cause problems changing these values to tf.zeros for conv_layer and  truncated_normal fc_layer, that is what's been used in cnn_mnist as well.\n",
    "```python\n",
    "## For conv_layer()\n",
    "b = tf.Variable(tf.zeros([size_out], dtype=tf.float32), name=\"B\")\n",
    "\n",
    "## For fc_layer()\n",
    "b = tf.Variable(tf.truncated_normal([size_out], stddev=0.1, dtype=tf.float32), name=\"B\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After removing constants\n",
    "![](img/lr005_steps500_remove_constants.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That didn't really help much. Accuracy is still around 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter size for the conv_layer is set to a 5 x 5 matrix. This could be an issue as our images 28 x 28. Let's try changing it to 4 x4, similar to cnn_mist program.\n",
    "```python\n",
    "w = tf.Variable(tf.truncated_normal([4, 4, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/lr005_steps500_remove_constants_4x4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the filter to 4x4 increased accuracy to about 40%.\n",
    "Let's try changing the fully connected output to 100 from 1024.\n",
    "```python\n",
    "if use_two_fc:\n",
    "    fc1 = fc_layer(flattened, 7 * 7 * conv2_features, 100, \"fc1\")\n",
    "    embedding_input = fc1\n",
    "    embedding_size = 100\n",
    "    logits = fc_layer(fc1, 100, 10, \"fc2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/lr005_steps500_rm_const_4x4_fc100.png)\n",
    "#### Changing the fully connected layer's output to 100 increased the accuracy to about 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try changing the optimizer to MomentumOptimizer.\n",
    "```python\n",
    "train_step = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(xent)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/lr005_steps500_rm_const_4x4_fc100_mon.png)\n",
    "#### We can see changing the optimizer increased the accuracy about 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's change the fully connected layer 1 size from 100 to 512. We can clearly see that increased accuracy of 98%\n",
    "![](img/final-500-512.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Cross entropy\n",
    "![](img/final-500-512-xent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fixed Code\n",
    "```python\n",
    "\n",
    "# Copyright 2017 Google, Inc. All Rights Reserved.\n",
    "#\n",
    "# ==============================================================================\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import urllib\n",
    "\n",
    "\n",
    "if sys.version_info[0] >= 3:\n",
    "    from urllib.request import urlretrieve\n",
    "else:\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "LOGDIR = 'log_mnist_500_512_2/'\n",
    "GITHUB_URL = 'https://raw.githubusercontent.com/mamcgrath/TensorBoard-TF-Dev-Summit-Tutorial/master/'\n",
    "GENERATIONS = 500\n",
    "\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(\n",
    "    train_dir=LOGDIR + 'data', one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "urlretrieve(GITHUB_URL + 'labels_1024.tsv', LOGDIR + 'labels_1024.tsv')\n",
    "urlretrieve(GITHUB_URL + 'sprite_1024.png', LOGDIR + 'sprite_1024.png')\n",
    "\n",
    "# Add convolution layer\n",
    "\n",
    "\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        #w = tf.Variable(tf.zeros([5, 5, size_in, size_out]), name=\"W\")\n",
    "        #b = tf.Variable(tf.zeros([size_out]), name=\"B\")\n",
    "        w = tf.Variable(tf.truncated_normal(\n",
    "            [4, 4, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros([size_out], dtype=tf.float32), name=\"B\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "# Add fully connected layer\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal(\n",
    "            [size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.truncated_normal(\n",
    "            [size_out], stddev=0.1, dtype=tf.float32), name=\"B\")\n",
    "        act = tf.nn.relu(tf.add(tf.matmul(input, w), b))\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "\n",
    "\n",
    "def mnist_model(learning_rate, use_two_conv, use_two_fc, conv1_features, conv2_features,\n",
    "                hparam, generations=500, fully_connected_size1=100):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Setup placeholders, and reshape the data\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 3)\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "    if use_two_conv:\n",
    "        conv1 = conv_layer(x_image, 1, conv1_features, \"conv1\")\n",
    "        conv_out = conv_layer(conv1, conv1_features, conv2_features, \"conv2\")\n",
    "    else:\n",
    "        conv1 = conv_layer(x_image, 1, conv2_features, \"conv\")\n",
    "        conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[\n",
    "                                  1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    flattened = tf.reshape(conv_out, [-1, 7 * 7 * conv2_features])\n",
    "\n",
    "    if use_two_fc:\n",
    "        fc1 = fc_layer(flattened, 7 * 7 * conv2_features, 100, \"fc1\")\n",
    "        embedding_input = fc1\n",
    "        embedding_size = 100\n",
    "        logits = fc_layer(fc1, 100, 10, \"fc2\")\n",
    "    else:\n",
    "        embedding_input = flattened\n",
    "        embedding_size = 7 * 7 * conv2_features\n",
    "        logits = fc_layer(flattened, 7 * 7 * conv2_features, 10, \"fc\")\n",
    "\n",
    "    with tf.name_scope(\"xent\"):\n",
    "        xent = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=logits, labels=y), name=\"xent\")\n",
    "        tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.MomentumOptimizer(\n",
    "            learning_rate, 0.9).minimize(xent)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    summ = tf.summary.merge_all()\n",
    "\n",
    "    embedding = tf.Variable(\n",
    "        tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "    assignment = embedding.assign(embedding_input)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = embedding.name\n",
    "    embedding_config.sprite.image_path = LOGDIR + 'sprite_1024.png'\n",
    "    embedding_config.metadata_path = LOGDIR + 'labels_1024.tsv'\n",
    "    # Specify the width and height of a single thumbnail.\n",
    "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(\n",
    "        writer, config)\n",
    "\n",
    "    for i in range(generations + 1):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        if i % 5 == 0:\n",
    "            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={\n",
    "                                           x: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "        if i % (generations / 4) == 0:\n",
    "            sess.run(assignment, feed_dict={\n",
    "                     x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "\n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv, conv1_features, conv2_features):\n",
    "    conv_param = \"conv2\" if use_two_conv else \"conv1\"\n",
    "    fc_param = \"fc2\" if use_two_fc else \"fc1\"\n",
    "    return \"lr_%.0E%s%s_%d_%d\" % (learning_rate, conv_param, fc_param, conv1_features, conv2_features)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # You can try adding some more learning rates\n",
    "    # for learning_rate in [1E-3, 1E-4, 1E-5]:\n",
    "    for learning_rate in [.005]:\n",
    "        # Include \"False\" as a value to try different model architectures\n",
    "        # for use_two_fc in [True, False]:\n",
    "        for use_two_fc in [True]:\n",
    "            # for use_two_conv in [True, False]:\n",
    "            for use_two_conv in [True]:\n",
    "                # for use_two_conv in [25, 32]:\n",
    "                for conv1_features in [32]:\n",
    "                    # for use_two_conv in [50, 64]:\n",
    "                    for conv2_features in [64]:\n",
    "                        # Construct a hyperparameter string for each one (example:\n",
    "                        # \"lr_1E-3fc2conv2\")\n",
    "                        hparam = make_hparam_string(\n",
    "                            learning_rate, use_two_fc, use_two_conv, conv1_features, conv2_features)\n",
    "                        print('Starting run for %s' % hparam)\n",
    "                        # this forces print-ed lines to show up.\n",
    "                        sys.stdout.flush()\n",
    "\n",
    "                        # Actually run with the new settings\n",
    "                        mnist_model(learning_rate, use_two_fc, use_two_conv, conv1_features,\n",
    "                                    conv2_features, hparam, GENERATIONS, fully_connected_size1=512)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. \n",
    "Run corrected version of mnist2.py for 4 different architectures (2 conv, 1 conv, 2 fully connected, 1 fully connected layer) and 3 values of the learning rate. As one learning rate choose the one you selected in Problem 1 and then add one smaller and one larger learning rate around that one. Capture Accuracy (summary) graphs and One of Histograms to demonstrate to us that your code is working. Please also capture an image of “colorful” T-SNE Embedding. Please be aware that you are running 12 models and the execution might take many minutes. You might want to run your models in smaller groups so that you see them finish their work without too much wait. Submit working code of  mnist2.py used in this problem. Collect execution times, final (smoothed) accuracies and final cross entropies for different models and provide tabulated presentation of the final results of different models (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Collect execution times, final (smoothed) accuracies and final cross entropies for different models and provide tabulated presentation of the final results of different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting log_mnist_fixed_1/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting log_mnist_fixed_1/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting log_mnist_fixed_1/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting log_mnist_fixed_1/data/t10k-labels-idx1-ubyte.gz\n",
      "Starting run for lr_1E-03conv2fc2\n",
      "[[853.5753090381622, 0.40000001, 1.4487785]]\n",
      "Starting run for lr_1E-03conv1fc2\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296]]\n",
      "Starting run for lr_1E-03conv2fc1\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539]]\n",
      "Starting run for lr_1E-03conv1fc1\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303]]\n",
      "Starting run for lr_5E-03conv2fc2\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074]]\n",
      "Starting run for lr_5E-03conv1fc2\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074], [809.6420028209686, 0.18000001, 2.1357055]]\n",
      "Starting run for lr_5E-03conv2fc1\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074], [809.6420028209686, 0.18000001, 2.1357055], [48.29083204269409, 0.54000002, 1.4167041]]\n",
      "Starting run for lr_5E-03conv1fc1\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074], [809.6420028209686, 0.18000001, 2.1357055], [48.29083204269409, 0.54000002, 1.4167041], [48.2823588848114, 0.72000003, 1.0157169]]\n",
      "Starting run for lr_1E-04conv2fc2\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074], [809.6420028209686, 0.18000001, 2.1357055], [48.29083204269409, 0.54000002, 1.4167041], [48.2823588848114, 0.72000003, 1.0157169], [829.7908608913422, 0.47, 1.6819137]]\n",
      "Starting run for lr_1E-04conv1fc2\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074], [809.6420028209686, 0.18000001, 2.1357055], [48.29083204269409, 0.54000002, 1.4167041], [48.2823588848114, 0.72000003, 1.0157169], [829.7908608913422, 0.47, 1.6819137], [821.5088160037994, 0.88999999, 0.36857432]]\n",
      "Starting run for lr_1E-04conv2fc1\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074], [809.6420028209686, 0.18000001, 2.1357055], [48.29083204269409, 0.54000002, 1.4167041], [48.2823588848114, 0.72000003, 1.0157169], [829.7908608913422, 0.47, 1.6819137], [821.5088160037994, 0.88999999, 0.36857432], [46.98151612281799, 0.33000001, 2.1960478]]\n",
      "Starting run for lr_1E-04conv1fc1\n",
      "[[853.5753090381622, 0.40000001, 1.4487785], [812.8208549022675, 0.31, 1.8688296], [47.31326913833618, 0.63999999, 1.0907539], [45.39625597000122, 0.47999999, 1.5451303], [808.9295129776001, 0.58999997, 1.4759074], [809.6420028209686, 0.18000001, 2.1357055], [48.29083204269409, 0.54000002, 1.4167041], [48.2823588848114, 0.72000003, 1.0157169], [829.7908608913422, 0.47, 1.6819137], [821.5088160037994, 0.88999999, 0.36857432], [46.98151612281799, 0.33000001, 2.1960478], [46.85387992858887, 0.41, 2.0141356]]\n",
      "                  Exec. Time  Accuracy  Cross Entropy\n",
      "lr_1E-03conv2fc2  853.575309      0.40       1.448779\n",
      "lr_1E-03conv1fc2  812.820855      0.31       1.868830\n",
      "lr_1E-03conv2fc1   47.313269      0.64       1.090754\n",
      "lr_1E-03conv1fc1   45.396256      0.48       1.545130\n",
      "lr_5E-03conv2fc2  808.929513      0.59       1.475907\n",
      "lr_5E-03conv1fc2  809.642003      0.18       2.135705\n",
      "lr_5E-03conv2fc1   48.290832      0.54       1.416704\n",
      "lr_5E-03conv1fc1   48.282359      0.72       1.015717\n",
      "lr_1E-04conv2fc2  829.790861      0.47       1.681914\n",
      "lr_1E-04conv1fc2  821.508816      0.89       0.368574\n",
      "lr_1E-04conv2fc1   46.981516      0.33       2.196048\n",
      "lr_1E-04conv1fc1   46.853880      0.41       2.014136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Copyright 2017 Google, Inc. All Rights Reserved.\n",
    "#\n",
    "# ==============================================================================\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if sys.version_info[0] >= 3:\n",
    "    from urllib.request import urlretrieve\n",
    "else:\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "LOGDIR = 'log_mnist_fixed_1/'\n",
    "GITHUB_URL = 'https://raw.githubusercontent.com/mamcgrath/TensorBoard-TF-Dev-Summit-Tutorial/master/'\n",
    "GENERATIONS = 500\n",
    "\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(\n",
    "    train_dir=LOGDIR + 'data', one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "#urlretrieve(GITHUB_URL + 'labels_1024.tsv', LOGDIR + 'labels_1024.tsv')\n",
    "#urlretrieve(GITHUB_URL + 'sprite_1024.png', LOGDIR + 'sprite_1024.png')\n",
    "\n",
    "# Add convolution layer\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        #w = tf.Variable(tf.zeros([5, 5, size_in, size_out]), name=\"W\")\n",
    "        #b = tf.Variable(tf.zeros([size_out]), name=\"B\")\n",
    "        w = tf.Variable(tf.truncated_normal(\n",
    "            [4, 4, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        #b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        b = tf.Variable(tf.zeros([size_out], dtype=tf.float32), name=\"B\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "# Add fully connected layer\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal(\n",
    "            [size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        #b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        #b = tf.Variable(tf.zeros([size_out], dtype=tf.float32), name=\"B\")\n",
    "        b = tf.Variable(tf.truncated_normal(\n",
    "            [size_out], stddev=0.1, dtype=tf.float32), name=\"B\")\n",
    "        act = tf.nn.relu(tf.add(tf.matmul(input, w), b))\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "\n",
    "\n",
    "def mnist_model(learning_rate, use_two_conv, use_two_fc,\n",
    "                hparam, conv1_features=32, conv2_features=64,\n",
    "                generations=500, fully_connected_size1=100):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Setup placeholders, and reshape the data\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 3)\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "    if use_two_conv:\n",
    "        conv1 = conv_layer(x_image, 1, conv1_features, \"conv1\")\n",
    "        conv_out = conv_layer(conv1, conv1_features, conv2_features, \"conv2\")\n",
    "        # missing tf.nn.max_pool here ??\n",
    "    else:\n",
    "        conv1 = conv_layer(x_image, 1, conv2_features, \"conv\")\n",
    "        # extra pooling here ??\n",
    "        conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1],\n",
    "                                  strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "    flattened = tf.reshape(conv_out, [-1, 7 * 7 * conv2_features])\n",
    "\n",
    "    if use_two_fc:\n",
    "        fc1 = fc_layer(flattened, 7 * 7 * conv2_features,\n",
    "                       fully_connected_size1, \"fc1\")\n",
    "        embedding_input = fc1\n",
    "        embedding_size = fully_connected_size1\n",
    "        logits = fc_layer(fc1, fully_connected_size1, 10, \"fc2\")\n",
    "    else:\n",
    "        embedding_input = flattened\n",
    "        embedding_size = 7 * 7 * conv2_features\n",
    "        logits = fc_layer(flattened, 7 * 7 * conv2_features, 10, \"fc\")\n",
    "\n",
    "    with tf.name_scope(\"xent\"):\n",
    "        xent = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                    labels=y), name=\"xent\")\n",
    "        tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        #train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "        train_step = tf.train.MomentumOptimizer(\n",
    "            learning_rate, 0.9).minimize(xent)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    summ = tf.summary.merge_all()\n",
    "\n",
    "    embedding = tf.Variable(tf.zeros([1024, embedding_size]),\n",
    "                            name=\"test_embedding\")\n",
    "    assignment = embedding.assign(embedding_input)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = embedding.name\n",
    "    embedding_config.sprite.image_path = LOGDIR + 'sprite_1024.png'\n",
    "    embedding_config.metadata_path = LOGDIR + 'labels_1024.tsv'\n",
    "    # Specify the width and height of a single thumbnail.\n",
    "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(\n",
    "        writer, config)\n",
    "\n",
    "    for i in range(generations + 1):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        if i % 5 == 0:\n",
    "            [train_accuracy, s] = sess.run([accuracy, summ],\n",
    "                                           feed_dict={x: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "        if i % (generations / 4) == 0:\n",
    "            sess.run(assignment,\n",
    "                     feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "    [train_accuracy, train_xent] = sess.run(\n",
    "        [accuracy, xent], feed_dict={x: batch[0], y: batch[1]})\n",
    "    return [train_accuracy, train_xent]\n",
    "\n",
    "\n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "    conv_param = \"conv2\" if use_two_conv else \"conv1\"\n",
    "    fc_param = \"fc2\" if use_two_fc else \"fc1\"\n",
    "    return \"lr_%.0E%s%s\" % (learning_rate, conv_param, fc_param)\n",
    "\n",
    "# error Starting run for lr_1E-03conv2fc1_25+50\n",
    "\n",
    "\n",
    "def main():\n",
    "    model_metrics_cols = ['Exec. Time', 'Accuracy', 'Cross Entropy']\n",
    "    model_metrics_result = []\n",
    "    model_metrics_idx = []\n",
    "    # You can try adding some more learning rates\n",
    "    # for learning_rate in [1E-3, 1E-4, 1E-5]:\n",
    "    for learning_rate in [1E-3, 5E-3, 1E-4]:\n",
    "        # Include \"False\" as a value to try different model architectures\n",
    "        # for use_two_fc in [True, False]:\n",
    "        for use_two_fc in [True, False]:\n",
    "            # for use_two_conv in [True, False]:\n",
    "            for use_two_conv in [True, False]:\n",
    "                # Construct a hyperparameter string for each one (example:\n",
    "                # \"lr_1E-3fc2conv2\")\n",
    "                hparam = make_hparam_string(learning_rate,\n",
    "                                            use_two_fc, use_two_conv)\n",
    "                print('Starting run for %s' % hparam)\n",
    "                # this forces print-ed lines to show up.\n",
    "                sys.stdout.flush()\n",
    "                start_time = time.time()\n",
    "                # Actually run with the new settings\n",
    "                accuracy, xent = mnist_model(\n",
    "                    learning_rate, use_two_fc,\n",
    "                    use_two_conv, hparam, GENERATIONS,\n",
    "                    fully_connected_size1=100)\n",
    "                total_time = time.time() - start_time\n",
    "                model_metrics_idx.append(hparam)\n",
    "                model_metrics_result.append(\n",
    "                    [total_time, accuracy, xent])\n",
    "                print(model_metrics_result)\n",
    "    df = pd.DataFrame(model_metrics_result,\n",
    "                      index=model_metrics_idx,\n",
    "                      columns=model_metrics_cols)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "                  Exec. Time  Accuracy  Cross Entropy\n",
    "lr_1E-03conv2fc2  121.250245      0.77       0.591943\n",
    "lr_5E-03conv2fc2  111.394670      0.32       1.591292\n",
    "lr_1E-04conv2fc2  115.845690      0.58       1.320814"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. \n",
    "Modify file cnn_mnist.py  so that it publishes its summaries to the TensorBoard. Describe changes you are making and provide images of Accuracy and Cross Entropy summaries as captured by the Tensor Board. Provide the Graph of your model. Describe the differences if any between the graph of this program and the graph generated by mnist2.py script running with 2 convolutional and 2 fully connected layers. Provide working code.  (35%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
